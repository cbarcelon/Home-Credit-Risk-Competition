{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Input/train_app_bureau.csv')\n",
    "test_df = pd.read_csv('../Input/test_app_bureau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# Label encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in train_df:\n",
    "    if train_df[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(train_df[col].unique())) <= 2:\n",
    "            # Train on the training data\n",
    "            le.fit(train_df[col])\n",
    "            # Transform both training and testing data\n",
    "            train_df[col] = le.transform(train_df[col])\n",
    "            test_df[col] = le.transform(test_df[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)\n",
    "\n",
    "# one-hot encoding of categorical variables\n",
    "\n",
    "train_df = pd.get_dummies(train_df)\n",
    "test_df = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_scores(df, num_folds, params, stratified = False, verbose = -1, \n",
    "              save_train_prediction = False, train_prediction_file_name = 'train_prediction.csv',\n",
    "              save_test_prediction = True, test_prediction_file_name = 'test_prediction.csv'):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    clf = LGBMClassifier(**params)\n",
    "\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "        \n",
    "    # Create arrays and dataframes to store results\n",
    "    train_pred = np.zeros(train_df.shape[0])\n",
    "    train_pred_proba = np.zeros(train_df.shape[0])\n",
    "\n",
    "    test_pred = np.zeros(train_df.shape[0])\n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    prediction = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    df_feature_importance = pd.DataFrame(index = feats)\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        print('Fold', n_fold, 'started at', time.ctime())\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = verbose, early_stopping_rounds = 200)\n",
    "\n",
    "        train_pred[train_idx] = clf.predict(train_x, num_iteration = clf.best_iteration_)\n",
    "        train_pred_proba[train_idx] = clf.predict_proba(train_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        test_pred[valid_idx] = clf.predict(valid_x, num_iteration = clf.best_iteration_)\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        prediction += \\\n",
    "                clf.predict_proba(test_df[feats], num_iteration = clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        df_feature_importance[n_fold] = pd.Series(clf.feature_importances_, index = feats)\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold, roc_auc_score(valid_y, test_pred_proba[valid_idx])))\n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    roc_auc_train = roc_auc_score(train_df['TARGET'], train_pred_proba)\n",
    "    precision_train = precision_score(train_df['TARGET'], train_pred, average = None)\n",
    "    recall_train = recall_score(train_df['TARGET'], train_pred, average = None)\n",
    "    \n",
    "    roc_auc_test = roc_auc_score(train_df['TARGET'], test_pred_proba)\n",
    "    precision_test = precision_score(train_df['TARGET'], test_pred, average = None)\n",
    "    recall_test = recall_score(train_df['TARGET'], test_pred, average = None)\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_test)\n",
    "    \n",
    "    df_feature_importance.fillna(0, inplace = True)\n",
    "    df_feature_importance['mean'] = df_feature_importance.mean(axis = 1)\n",
    "    \n",
    "    # Write prediction files\n",
    "    if save_train_prediction:\n",
    "        df_prediction = train_df[['SK_ID_CURR', 'TARGET']]\n",
    "        df_prediction['Prediction'] = test_pred_proba\n",
    "        df_prediction.to_csv(train_prediction_file_name, index = False)\n",
    "        del df_prediction\n",
    "        gc.collect()\n",
    "\n",
    "    if save_test_prediction:\n",
    "        df_prediction = test_df[['SK_ID_CURR']]\n",
    "        df_prediction['TARGET'] = prediction\n",
    "        df_prediction.to_csv(test_prediction_file_name, index = False)\n",
    "        del df_prediction\n",
    "        gc.collect()\n",
    "    \n",
    "    return df_feature_importance, \\\n",
    "           [roc_auc_train, roc_auc_test,\n",
    "            precision_train[0], precision_test[0], precision_train[1], precision_test[1],\n",
    "            recall_train[0], recall_test[0], recall_train[1], recall_test[1], 0]\n",
    "\n",
    "def display_folds_importances(feature_importance_df_, n_folds = 5):\n",
    "    n_columns = 3\n",
    "    n_rows = (n_folds + 1) // n_columns\n",
    "    _, axes = plt.subplots(n_rows, n_columns, figsize=(8 * n_columns, 8 * n_rows))\n",
    "    for i in range(n_folds):\n",
    "        sns.barplot(x = i, y = 'index', data = feature_importance_df_.reset_index().sort_values(i, ascending = False).head(20), \n",
    "                    ax = axes[i // n_columns, i % n_columns])\n",
    "    sns.barplot(x = 'mean', y = 'index', data = feature_importance_df_.reset_index().sort_values('mean', ascending = False).head(20), \n",
    "                    ax = axes[n_rows - 1, n_columns - 1])\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "lgbm_params = {\n",
    "            'nthread': -1,\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': .02,\n",
    "            'num_leaves': 34,\n",
    "            'colsample_bytree': .9497036,\n",
    "            'subsample': .8715623,\n",
    "            'max_depth': 8,\n",
    "            'reg_alpha': .041545473,\n",
    "            'reg_lambda': .0735294,\n",
    "            'min_split_gain': .0222415,\n",
    "            'min_child_weight': 39.3259775,\n",
    "            'silent': -1,\n",
    "            'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.append(test_df)\n",
    "del train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307511, 455), test shape: (48744, 455)\n",
      "Fold 0 started at Fri Aug 10 10:47:22 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1164]\ttraining's auc: 0.839091\tvalid_1's auc: 0.772007\n",
      "Fold  0 AUC : 0.772007\n",
      "Fold 1 started at Fri Aug 10 10:52:25 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1275]\ttraining's auc: 0.844128\tvalid_1's auc: 0.770086\n",
      "Fold  1 AUC : 0.770086\n",
      "Fold 2 started at Fri Aug 10 10:57:49 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1212]\ttraining's auc: 0.844505\tvalid_1's auc: 0.764642\n",
      "Fold  2 AUC : 0.764642\n",
      "Fold 3 started at Fri Aug 10 11:02:58 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1367]\ttraining's auc: 0.849629\tvalid_1's auc: 0.768767\n",
      "Fold  3 AUC : 0.768767\n",
      "Fold 4 started at Fri Aug 10 11:08:32 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1246]\ttraining's auc: 0.844514\tvalid_1's auc: 0.771191\n",
      "Fold  4 AUC : 0.771191\n",
      "Full AUC score 0.769334\n"
     ]
    }
   ],
   "source": [
    "feature_importance, scor = cv_scores(df, 5, lgbm_params, test_prediction_file_name = '../Submissions/app_bureau_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
