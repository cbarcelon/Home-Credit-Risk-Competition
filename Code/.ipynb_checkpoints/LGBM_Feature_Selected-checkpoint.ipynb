{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca25a2f95f0fc9498b9b2e3a9d96607fbb682015"
   },
   "source": [
    "# Home Credit Default Risk 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2776978fa169449d5bf3c8f036668afe10a47502"
   },
   "source": [
    "__Warning!__ This kernel cannot run on Kaggle: not enough memory. But the code works fine and quickly on the local computer with the same amount of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e45783c7652aae4607fc8c1ac79c979d7b387043"
   },
   "source": [
    "Based on kernels: \n",
    "\n",
    "- https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features\n",
    "\n",
    "- https://www.kaggle.com/poohtls/fork-of-fork-lightgbm-with-simple-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "cc4088625ae2209899d05c70dfd7bcb108cb4c3a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "be294207f4e12ccf54d922814789b27998577dca"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "962799c45d0c88ee9237cb0e202b11758abac536"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "42960cc0257a40fee0876294c6956e0aeba23023"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0b5e7cfa7c94294ad8b1eab00438592d24450e11"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f7495063700c9e611ea1e27f90f40acd5085cae"
   },
   "source": [
    "## Optimization LGBM parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9148f2a806be7e22a5cfb90442d82a72e1da4084"
   },
   "source": [
    "### Optimization and visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(data, verbose = True):\n",
    "    start_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage of dataframe: {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        col_type = data[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = data[col].min()\n",
    "            c_max = data[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    data[col] = data[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    data[col] = data[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    data[col] = data[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    data[col] = data[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data[col] = data[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data[col] = data[col].astype(np.float32)\n",
    "                else:\n",
    "                    data[col] = data[col].astype(np.float64)\n",
    "\n",
    "    end_mem = data.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Memory usage after optimization: {:.2f} MB'.format(end_mem))\n",
    "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b440750e95bc79ad0603245387b08aefe048b0af"
   },
   "outputs": [],
   "source": [
    "def cv_scores(df, num_folds, params, stratified = False, verbose = -1, \n",
    "              save_train_prediction = False, train_prediction_file_name = 'train_prediction.csv',\n",
    "              save_test_prediction = True, test_prediction_file_name = 'test_prediction.csv'):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    clf = LGBMClassifier(**params)\n",
    "\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "        \n",
    "    # Create arrays and dataframes to store results\n",
    "    train_pred = np.zeros(train_df.shape[0])\n",
    "    train_pred_proba = np.zeros(train_df.shape[0])\n",
    "\n",
    "    test_pred = np.zeros(train_df.shape[0])\n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    prediction = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    df_feature_importance = pd.DataFrame(index = feats)\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        print('Fold', n_fold, 'started at', time.ctime())\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = verbose, early_stopping_rounds = 200)\n",
    "\n",
    "        train_pred[train_idx] = clf.predict(train_x, num_iteration = clf.best_iteration_)\n",
    "        train_pred_proba[train_idx] = clf.predict_proba(train_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        test_pred[valid_idx] = clf.predict(valid_x, num_iteration = clf.best_iteration_)\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        prediction += \\\n",
    "                clf.predict_proba(test_df[feats], num_iteration = clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        df_feature_importance[n_fold] = pd.Series(clf.feature_importances_, index = feats)\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold, roc_auc_score(valid_y, test_pred_proba[valid_idx])))\n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    roc_auc_train = roc_auc_score(train_df['TARGET'], train_pred_proba)\n",
    "    precision_train = precision_score(train_df['TARGET'], train_pred, average = None)\n",
    "    recall_train = recall_score(train_df['TARGET'], train_pred, average = None)\n",
    "    \n",
    "    roc_auc_test = roc_auc_score(train_df['TARGET'], test_pred_proba)\n",
    "    precision_test = precision_score(train_df['TARGET'], test_pred, average = None)\n",
    "    recall_test = recall_score(train_df['TARGET'], test_pred, average = None)\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_test)\n",
    "    \n",
    "    df_feature_importance.fillna(0, inplace = True)\n",
    "    df_feature_importance['mean'] = df_feature_importance.mean(axis = 1)\n",
    "    \n",
    "    # Write prediction files\n",
    "    if save_train_prediction:\n",
    "        df_prediction = train_df[['SK_ID_CURR', 'TARGET']]\n",
    "        df_prediction['Prediction'] = test_pred_proba\n",
    "        df_prediction.to_csv(train_prediction_file_name, index = False)\n",
    "        del df_prediction\n",
    "        gc.collect()\n",
    "\n",
    "    if save_test_prediction:\n",
    "        df_prediction = test_df[['SK_ID_CURR']]\n",
    "        df_prediction['TARGET'] = prediction\n",
    "        df_prediction.to_csv(test_prediction_file_name, index = False)\n",
    "        del df_prediction\n",
    "        gc.collect()\n",
    "    \n",
    "    return df_feature_importance, \\\n",
    "           [roc_auc_train, roc_auc_test,\n",
    "            precision_train[0], precision_test[0], precision_train[1], precision_test[1],\n",
    "            recall_train[0], recall_test[0], recall_train[1], recall_test[1], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "9c8cd095e8a6472475c239973fc25af25e10534e"
   },
   "outputs": [],
   "source": [
    "def display_folds_importances(feature_importance_df_, n_folds = 5):\n",
    "    n_columns = 3\n",
    "    n_rows = (n_folds + 1) // n_columns\n",
    "    _, axes = plt.subplots(n_rows, n_columns, figsize=(8 * n_columns, 8 * n_rows))\n",
    "    for i in range(n_folds):\n",
    "        sns.barplot(x = i, y = 'index', data = feature_importance_df_.reset_index().sort_values(i, ascending = False).head(20), \n",
    "                    ax = axes[i // n_columns, i % n_columns])\n",
    "    sns.barplot(x = 'mean', y = 'index', data = feature_importance_df_.reset_index().sort_values('mean', ascending = False).head(20), \n",
    "                    ax = axes[n_rows - 1, n_columns - 1])\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4549a6ebeb42683066f5a2d1da493cc98135a61d"
   },
   "source": [
    "### Table for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f0714d9b17343b47fb218d6559906018e5673735"
   },
   "outputs": [],
   "source": [
    "scores_index = [\n",
    "    'roc_auc_train', 'roc_auc_test', \n",
    "    'precision_train_0', 'precision_test_0', \n",
    "    'precision_train_1', 'precision_test_1', \n",
    "    'recall_train_0', 'recall_test_0', \n",
    "    'recall_train_1', 'recall_test_1', \n",
    "    'LB'\n",
    "]\n",
    "\n",
    "scores = pd.DataFrame(index = scores_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe4fb091c39f4edd0bbf997bcc5630e35b47228b"
   },
   "source": [
    "### First scores with parameters from Tilii kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "bba1ec6f8d9f45f0c0b0d5c927df6f8b893c4560"
   },
   "outputs": [],
   "source": [
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "lgbm_params = {\n",
    "            'nthread': -1,\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': .02,\n",
    "            'num_leaves': 34,\n",
    "            'colsample_bytree': .9497036,\n",
    "            'subsample': .8715623,\n",
    "            'max_depth': 8,\n",
    "            'reg_alpha': .041545473,\n",
    "            'reg_lambda': .0735294,\n",
    "            'min_split_gain': .0222415,\n",
    "            'min_child_weight': 39.3259775,\n",
    "            'silent': -1,\n",
    "            'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356244, 858)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Input/Aggregated_Removed_Empty_60.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe: 2331.98 MB\n",
      "Memory usage after optimization: 852.07 MB\n",
      "Decreased by 63.5%\n"
     ]
    }
   ],
   "source": [
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "a0c18d584ffb1abbc944ae5f2f78e9b30b67c3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307500, 858), test shape: (48744, 858)\n",
      "Fold 0 started at Wed Aug 15 11:28:10 2018\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "bad allocation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7aec1866fd57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_importance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlgbm_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_prediction_file_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'feature_selection_predictions_1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-b0080b8f89d0>\u001b[0m in \u001b[0;36mcv_scores\u001b[1;34m(df, num_folds, params, stratified, verbose, save_train_prediction, train_prediction_file_name, save_test_prediction, test_prediction_file_name)\u001b[0m\n\u001b[0;32m     37\u001b[0m         clf.fit(train_x, train_y, \n\u001b[0;32m     38\u001b[0m                 \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 verbose = verbose, early_stopping_rounds = 200)\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtrain_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    693\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[0;32m   1305\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[1;32m-> 1307\u001b[1;33m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1308\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    858\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init_from_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \"\"\"\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: bad allocation"
     ]
    }
   ],
   "source": [
    "feature_importance, scor = cv_scores(df, 5, lgbm_params, test_prediction_file_name = 'feature_selection_predictions_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da6f3a9750b217acb21bc76a34239aa438567228"
   },
   "outputs": [],
   "source": [
    "step = 'Tilii`s Bayesian optimization'\n",
    "scores[step] = scor\n",
    "scores.loc['LB', step] = .797\n",
    "scores.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b3d39f6ddc4ee9faec197ff043c1955dbafd90a"
   },
   "outputs": [],
   "source": [
    "display_folds_importances(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4b2b24d30d0283b4eae36dba1cfc166fc70dcdc"
   },
   "outputs": [],
   "source": [
    "feature_importance[feature_importance['mean'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ecd58af84525839510d1669efb1cc0bb251e310"
   },
   "outputs": [],
   "source": [
    "feature_importance.sort_values('mean', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9cd32bd6d9279b1575d87877790dc235283903a8"
   },
   "source": [
    "### New Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "64a682f66238fa787178ee8302ea5273c8646555"
   },
   "outputs": [],
   "source": [
    "def lgbm_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = LGBMClassifier(**params, n_estimators = 50000, nthread = -1)\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = KFold(n_splits = 2, shuffle = True, random_state = 1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "556c867c985588834ef080975c6be88a5c54cd90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample | \n"
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': (0.6, 1),\n",
    "          'learning_rate': (.01, .04), \n",
    "          'num_leaves': (30, 50), \n",
    "          'subsample': (0.8, 1), \n",
    "          'max_depth': (5, 15), \n",
    "          'reg_alpha': (.03, .05), \n",
    "          'reg_lambda': (.06, .1), \n",
    "          'min_split_gain': (.001, .03),\n",
    "          'min_child_weight': (30, 50)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 10, n_iter = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e79d57053f66ddc8c166e705514030870bc67d0e"
   },
   "outputs": [],
   "source": [
    "best_params = bo.res['max']['max_params']\n",
    "best_params['num_leaves'] = int(best_params['num_leaves'])\n",
    "best_params['max_depth'] = int(best_params['max_depth'])\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e07d4e2ce1ea005682fe5cb68a7e8c89f2e938da"
   },
   "outputs": [],
   "source": [
    "bo.res['max']['max_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7bb52b49aa2647c5535031dd95ef516670ec175"
   },
   "outputs": [],
   "source": [
    "feature_importance, scor = cv_scores(df, 5, best_params, test_prediction_file_name = 'feature_selection_bayes_prediction_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a2f3ff539febdda719dc338caa89d6cd02a21c7"
   },
   "outputs": [],
   "source": [
    "#step = 'Bayesian optimization for new set'\n",
    "#scores[step] = scor\n",
    "#scores.loc['LB', step] = .797\n",
    "#scores.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "108d69bb84fc2899d246c748b5173719622f4aa2"
   },
   "outputs": [],
   "source": [
    "#display_folds_importances(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cf68f0e2afb1ac125af0dbf14cce64455965e5a"
   },
   "outputs": [],
   "source": [
    "#feature_importance[feature_importance['mean'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65e0e56886249c8b1c3acae9e0411a34baf75fe5"
   },
   "outputs": [],
   "source": [
    "#feature_importance.sort_values('mean', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7394bcdf79fc237f81aa13636f39783e42d84a41"
   },
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
