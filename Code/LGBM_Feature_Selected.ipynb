{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca25a2f95f0fc9498b9b2e3a9d96607fbb682015"
   },
   "source": [
    "# Home Credit Default Risk 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2776978fa169449d5bf3c8f036668afe10a47502"
   },
   "source": [
    "__Warning!__ This kernel cannot run on Kaggle: not enough memory. But the code works fine and quickly on the local computer with the same amount of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e45783c7652aae4607fc8c1ac79c979d7b387043"
   },
   "source": [
    "Based on kernels: \n",
    "\n",
    "- https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features\n",
    "\n",
    "- https://www.kaggle.com/poohtls/fork-of-fork-lightgbm-with-simple-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "cc4088625ae2209899d05c70dfd7bcb108cb4c3a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "be294207f4e12ccf54d922814789b27998577dca"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "962799c45d0c88ee9237cb0e202b11758abac536"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "42960cc0257a40fee0876294c6956e0aeba23023"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0b5e7cfa7c94294ad8b1eab00438592d24450e11"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f7495063700c9e611ea1e27f90f40acd5085cae"
   },
   "source": [
    "## Optimization LGBM parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9148f2a806be7e22a5cfb90442d82a72e1da4084"
   },
   "source": [
    "### Optimization and visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b440750e95bc79ad0603245387b08aefe048b0af"
   },
   "outputs": [],
   "source": [
    "def cv_scores(df, num_folds, params, stratified = False, verbose = -1, \n",
    "              save_train_prediction = False, train_prediction_file_name = 'train_prediction.csv',\n",
    "              save_test_prediction = True, test_prediction_file_name = 'test_prediction.csv'):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    clf = LGBMClassifier(**params)\n",
    "\n",
    "    # Divide in training/validation and test data\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "    else:\n",
    "        folds = KFold(n_splits = num_folds, shuffle = True, random_state = 1001)\n",
    "        \n",
    "    # Create arrays and dataframes to store results\n",
    "    train_pred = np.zeros(train_df.shape[0])\n",
    "    train_pred_proba = np.zeros(train_df.shape[0])\n",
    "\n",
    "    test_pred = np.zeros(train_df.shape[0])\n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    prediction = np.zeros(test_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    df_feature_importance = pd.DataFrame(index = feats)\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        print('Fold', n_fold, 'started at', time.ctime())\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = verbose, early_stopping_rounds = 200)\n",
    "\n",
    "        train_pred[train_idx] = clf.predict(train_x, num_iteration = clf.best_iteration_)\n",
    "        train_pred_proba[train_idx] = clf.predict_proba(train_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        test_pred[valid_idx] = clf.predict(valid_x, num_iteration = clf.best_iteration_)\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        prediction += \\\n",
    "                clf.predict_proba(test_df[feats], num_iteration = clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        df_feature_importance[n_fold] = pd.Series(clf.feature_importances_, index = feats)\n",
    "        \n",
    "        print('Fold %2d AUC : %.6f' % (n_fold, roc_auc_score(valid_y, test_pred_proba[valid_idx])))\n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    roc_auc_train = roc_auc_score(train_df['TARGET'], train_pred_proba)\n",
    "    precision_train = precision_score(train_df['TARGET'], train_pred, average = None)\n",
    "    recall_train = recall_score(train_df['TARGET'], train_pred, average = None)\n",
    "    \n",
    "    roc_auc_test = roc_auc_score(train_df['TARGET'], test_pred_proba)\n",
    "    precision_test = precision_score(train_df['TARGET'], test_pred, average = None)\n",
    "    recall_test = recall_score(train_df['TARGET'], test_pred, average = None)\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_test)\n",
    "    \n",
    "    df_feature_importance.fillna(0, inplace = True)\n",
    "    df_feature_importance['mean'] = df_feature_importance.mean(axis = 1)\n",
    "    \n",
    "    # Write prediction files\n",
    "    if save_train_prediction:\n",
    "        df_prediction = train_df[['SK_ID_CURR', 'TARGET']]\n",
    "        df_prediction['Prediction'] = test_pred_proba\n",
    "        df_prediction.to_csv(train_prediction_file_name, index = False)\n",
    "        del df_prediction\n",
    "        gc.collect()\n",
    "\n",
    "    if save_test_prediction:\n",
    "        df_prediction = test_df[['SK_ID_CURR']]\n",
    "        df_prediction['TARGET'] = prediction\n",
    "        df_prediction.to_csv(test_prediction_file_name, index = False)\n",
    "        del df_prediction\n",
    "        gc.collect()\n",
    "    \n",
    "    return df_feature_importance, \\\n",
    "           [roc_auc_train, roc_auc_test,\n",
    "            precision_train[0], precision_test[0], precision_train[1], precision_test[1],\n",
    "            recall_train[0], recall_test[0], recall_train[1], recall_test[1], 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9c8cd095e8a6472475c239973fc25af25e10534e"
   },
   "outputs": [],
   "source": [
    "def display_folds_importances(feature_importance_df_, n_folds = 5):\n",
    "    n_columns = 3\n",
    "    n_rows = (n_folds + 1) // n_columns\n",
    "    _, axes = plt.subplots(n_rows, n_columns, figsize=(8 * n_columns, 8 * n_rows))\n",
    "    for i in range(n_folds):\n",
    "        sns.barplot(x = i, y = 'index', data = feature_importance_df_.reset_index().sort_values(i, ascending = False).head(20), \n",
    "                    ax = axes[i // n_columns, i % n_columns])\n",
    "    sns.barplot(x = 'mean', y = 'index', data = feature_importance_df_.reset_index().sort_values('mean', ascending = False).head(20), \n",
    "                    ax = axes[n_rows - 1, n_columns - 1])\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4549a6ebeb42683066f5a2d1da493cc98135a61d"
   },
   "source": [
    "### Table for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f0714d9b17343b47fb218d6559906018e5673735"
   },
   "outputs": [],
   "source": [
    "scores_index = [\n",
    "    'roc_auc_train', 'roc_auc_test', \n",
    "    'precision_train_0', 'precision_test_0', \n",
    "    'precision_train_1', 'precision_test_1', \n",
    "    'recall_train_0', 'recall_test_0', \n",
    "    'recall_train_1', 'recall_test_1', \n",
    "    'LB'\n",
    "]\n",
    "\n",
    "scores = pd.DataFrame(index = scores_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe4fb091c39f4edd0bbf997bcc5630e35b47228b"
   },
   "source": [
    "### First scores with parameters from Tilii kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "bba1ec6f8d9f45f0c0b0d5c927df6f8b893c4560"
   },
   "outputs": [],
   "source": [
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "lgbm_params = {\n",
    "            'nthread': -1,\n",
    "            'n_estimators': 50000,\n",
    "            'learning_rate': .02,\n",
    "            'num_leaves': 34,\n",
    "            'colsample_bytree': .9497036,\n",
    "            'subsample': .8715623,\n",
    "            'max_depth': 8,\n",
    "            'reg_alpha': .041545473,\n",
    "            'reg_lambda': .0735294,\n",
    "            'min_split_gain': .0222415,\n",
    "            'min_child_weight': 39.3259775,\n",
    "            'silent': -1,\n",
    "            'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356244, 889)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Input/All_Features_Cleaned_Removed_Correlated_Empty.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "a0c18d584ffb1abbc944ae5f2f78e9b30b67c3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LightGBM. Train shape: (307500, 889), test shape: (48744, 889)\n",
      "Fold 0 started at Wed Aug 15 03:56:40 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1069]\ttraining's auc: 0.874257\tvalid_1's auc: 0.790595\n",
      "Fold  0 AUC : 0.790595\n",
      "Fold 1 started at Wed Aug 15 04:01:04 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1336]\ttraining's auc: 0.887316\tvalid_1's auc: 0.794622\n",
      "Fold  1 AUC : 0.794622\n",
      "Fold 2 started at Wed Aug 15 04:06:09 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1429]\ttraining's auc: 0.891935\tvalid_1's auc: 0.788349\n",
      "Fold  2 AUC : 0.788349\n",
      "Fold 3 started at Wed Aug 15 04:11:27 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1309]\ttraining's auc: 0.885315\tvalid_1's auc: 0.794118\n",
      "Fold  3 AUC : 0.794118\n",
      "Fold 4 started at Wed Aug 15 04:16:26 2018\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1514]\ttraining's auc: 0.896418\tvalid_1's auc: 0.790417\n",
      "Fold  4 AUC : 0.790417\n",
      "Full AUC score 0.791554\n"
     ]
    }
   ],
   "source": [
    "feature_importance, scor = cv_scores(df, 5, lgbm_params, test_prediction_file_name = 'feature_selection_predictions_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da6f3a9750b217acb21bc76a34239aa438567228"
   },
   "outputs": [],
   "source": [
    "step = 'Tilii`s Bayesian optimization'\n",
    "scores[step] = scor\n",
    "scores.loc['LB', step] = .797\n",
    "scores.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b3d39f6ddc4ee9faec197ff043c1955dbafd90a"
   },
   "outputs": [],
   "source": [
    "display_folds_importances(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4b2b24d30d0283b4eae36dba1cfc166fc70dcdc"
   },
   "outputs": [],
   "source": [
    "feature_importance[feature_importance['mean'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ecd58af84525839510d1669efb1cc0bb251e310"
   },
   "outputs": [],
   "source": [
    "feature_importance.sort_values('mean', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9cd32bd6d9279b1575d87877790dc235283903a8"
   },
   "source": [
    "### New Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "64a682f66238fa787178ee8302ea5273c8646555"
   },
   "outputs": [],
   "source": [
    "def lgbm_evaluate(**params):\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "        \n",
    "    clf = LGBMClassifier(**params, n_estimators = 50000, nthread = -1)\n",
    "\n",
    "    train_df = df[df['TARGET'].notnull()]\n",
    "    test_df = df[df['TARGET'].isnull()]\n",
    "\n",
    "    folds = KFold(n_splits = 2, shuffle = True, random_state = 1001)\n",
    "        \n",
    "    test_pred_proba = np.zeros(train_df.shape[0])\n",
    "    \n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf.fit(train_x, train_y, \n",
    "                eval_set = [(train_x, train_y), (valid_x, valid_y)], eval_metric = 'auc', \n",
    "                verbose = False, early_stopping_rounds = 100)\n",
    "\n",
    "        test_pred_proba[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        del train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "\n",
    "    return roc_auc_score(train_df['TARGET'], test_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "556c867c985588834ef080975c6be88a5c54cd90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   min_split_gain |   num_leaves |   reg_alpha |   reg_lambda |   subsample | \n"
     ]
    }
   ],
   "source": [
    "params = {'colsample_bytree': (0.6, 1),\n",
    "          'learning_rate': (.01, .04), \n",
    "          'num_leaves': (30, 50), \n",
    "          'subsample': (0.8, 1), \n",
    "          'max_depth': (5, 15), \n",
    "          'reg_alpha': (.03, .05), \n",
    "          'reg_lambda': (.06, .1), \n",
    "          'min_split_gain': (.001, .03),\n",
    "          'min_child_weight': (30, 50)}\n",
    "bo = BayesianOptimization(lgbm_evaluate, params)\n",
    "bo.maximize(init_points = 10, n_iter = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e79d57053f66ddc8c166e705514030870bc67d0e"
   },
   "outputs": [],
   "source": [
    "best_params = bo.res['max']['max_params']\n",
    "best_params['num_leaves'] = int(best_params['num_leaves'])\n",
    "best_params['max_depth'] = int(best_params['max_depth'])\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e07d4e2ce1ea005682fe5cb68a7e8c89f2e938da"
   },
   "outputs": [],
   "source": [
    "bo.res['max']['max_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7bb52b49aa2647c5535031dd95ef516670ec175"
   },
   "outputs": [],
   "source": [
    "feature_importance, scor = cv_scores(df, 5, best_params, test_prediction_file_name = 'feature_selection_bayes_prediction_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a2f3ff539febdda719dc338caa89d6cd02a21c7"
   },
   "outputs": [],
   "source": [
    "#step = 'Bayesian optimization for new set'\n",
    "#scores[step] = scor\n",
    "#scores.loc['LB', step] = .797\n",
    "#scores.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "108d69bb84fc2899d246c748b5173719622f4aa2"
   },
   "outputs": [],
   "source": [
    "#display_folds_importances(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cf68f0e2afb1ac125af0dbf14cce64455965e5a"
   },
   "outputs": [],
   "source": [
    "#feature_importance[feature_importance['mean'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65e0e56886249c8b1c3acae9e0411a34baf75fe5"
   },
   "outputs": [],
   "source": [
    "#feature_importance.sort_values('mean', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7394bcdf79fc237f81aa13636f39783e42d84a41"
   },
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
